{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Celda 1: Importaciones y Configuración Inicial del Logging\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-05-30 15:42:55 - INFO - Agent GOSOM MVP Initialized (inicio de sesión de logger).\n",
      "2025-05-30 15:42:55 - INFO - [ OK ] Archivo de configuración 'c:\\BAU\\1 TRABAJO\\REPOSITORIOS\\ETL-GMAPS\\etl-gmaps\\0_AGENTE_GOSOM\\config\\parameters_default.json' cargado correctamente.\n",
      "2025-05-30 15:42:55 - INFO - \n",
      "================================================================================\n",
      "CARGANDO PARÁMETROS GLOBALES DEL AGENTE\n",
      "================================================================================\n",
      "2025-05-30 15:42:55 - INFO - [INFO] Lenguaje para scraping: es\n",
      "2025-05-30 15:42:55 - INFO - [INFO] Profundidad de búsqueda por defecto: 2\n",
      "2025-05-30 15:42:55 - INFO - [INFO] Prefijo para archivos de resultados: gmaps_data_\n",
      "2025-05-30 15:42:55 - INFO - [INFO] Carpeta para CSVs crudos: c:\\BAU\\1 TRABAJO\\REPOSITORIOS\\ETL-GMAPS\\etl-gmaps\\0_AGENTE_GOSOM\\data\\raw\n",
      "2025-05-30 15:42:55 - INFO - [INFO] Carpeta para CSVs procesados: c:\\BAU\\1 TRABAJO\\REPOSITORIOS\\ETL-GMAPS\\etl-gmaps\\0_AGENTE_GOSOM\\data\\processed\n",
      "2025-05-30 15:42:55 - INFO - [ OK ] Carpetas de datos RAW y PROCESSED verificadas/creadas.\n",
      "2025-05-30 15:42:55 - INFO - [INFO] Coordenadas cargadas para 4 ciudades.\n",
      "2025-05-30 15:42:55 - INFO - [INFO] Celda 1 completada: Logger y configuración base listos.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[DEBUG RUTA] Directorio actual del notebook (CWD): c:\\BAU\\1 TRABAJO\\REPOSITORIOS\\ETL-GMAPS\\etl-gmaps\\0_AGENTE_GOSOM\\notebooks\n",
      "[DEBUG RUTA] Directorio del agente GOSOM deducido: c:\\BAU\\1 TRABAJO\\REPOSITORIOS\\ETL-GMAPS\\etl-gmaps\\0_AGENTE_GOSOM\n",
      "[DEBUG RUTA] Intentando cargar config desde: c:\\BAU\\1 TRABAJO\\REPOSITORIOS\\ETL-GMAPS\\etl-gmaps\\0_AGENTE_GOSOM\\config\\parameters_default.json\n",
      "\n",
      "        ********************************************************************************\n",
      "        *                     G M A P S   S C R A P E R   A G E N T                    *\n",
      "        *                         ( Avalian Project - MVP )                          *\n",
      "        ********************************************************************************\n",
      "        \n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Celda 2 (Revisada): Funciones para Leer Archivos de Keywords\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-05-30 15:42:55 - INFO - \n",
      "================================================================================\n",
      "DEFINIENDO FUNCIONES DE UTILIDAD\n",
      "================================================================================\n",
      "2025-05-30 15:42:55 - INFO - \n",
      "------------------------------------------------------------\n",
      "Función para Cargar Keywords\n",
      "------------------------------------------------------------\n",
      "2025-05-30 15:42:55 - INFO - \n",
      "------------------------------------------------------------\n",
      "Probando Carga de Keywords\n",
      "------------------------------------------------------------\n",
      "2025-05-30 15:42:55 - INFO - [INFO] Intentando cargar keywords para la ciudad de prueba: 'neuquen'\n",
      "2025-05-30 15:42:55 - INFO - [ OK ] Keywords cargadas para 'neuquen' desde 'c:\\BAU\\1 TRABAJO\\REPOSITORIOS\\ETL-GMAPS\\etl-gmaps\\0_AGENTE_GOSOM\\config\\keywords_neuquen.csv': 4 keywords.\n",
      "2025-05-30 15:42:55 - INFO - [INFO] Ejemplo de keywords para Neuquen (primeras 3 si hay): ['Contadores en Neuquen', 'Empresas de servicios en Neuquen', 'Consultorios medicos en Neuquen']\n",
      "2025-05-30 15:42:55 - INFO - [INFO] Intentando cargar keywords para una ciudad de prueba que no existe: 'ciudad_totalmente_inventada'\n",
      "2025-05-30 15:42:55 - WARNING - [WARN] No se encontraron keywords válidas (o el archivo está vacío) en 'c:\\BAU\\1 TRABAJO\\REPOSITORIOS\\ETL-GMAPS\\etl-gmaps\\0_AGENTE_GOSOM\\config\\keywords_ciudad_totalmente_inventada.csv' para 'ciudad_totalmente_inventada'.\n",
      "2025-05-30 15:42:55 - INFO - [INFO] Celda 2 completada: Función de carga de keywords definida y probada.\n"
     ]
    }
   ],
   "source": [
    "# Celda 2: Funciones para Leer Archivos de Keywords\n",
    "\n",
    "logger.section(\"Definiendo Funciones de Utilidad\")\n",
    "logger.subsection(\"Función para Cargar Keywords\")\n",
    "\n",
    "def load_keywords_from_csv(city_name_key):\n",
    "    \"\"\"\n",
    "    Carga keywords desde un archivo CSV específico para una clave de ciudad.\n",
    "    La clave de ciudad se usa para encontrar el archivo en 'config/keywords_<city_name_key>.csv'\n",
    "    \"\"\"\n",
    "    if CONFIG_DIR is None:\n",
    "        logger.error(\"Directorio de configuración (CONFIG_DIR) no está definido. No se pueden cargar keywords.\")\n",
    "        return []\n",
    "\n",
    "    filepath = os.path.join(CONFIG_DIR, f'keywords_{city_name_key.lower()}.csv')\n",
    "    \n",
    "    try:\n",
    "        with open(filepath, 'r', encoding='utf-8') as f:\n",
    "            keywords = [line.strip() for line in f if line.strip()] # Filtra líneas vacías y quita espacios\n",
    "        \n",
    "        if keywords:\n",
    "            logger.success(f\"Keywords cargadas para '{city_name_key}' desde '{filepath}': {len(keywords)} keywords.\")\n",
    "        else:\n",
    "            logger.warning(f\"No se encontraron keywords válidas (o el archivo está vacío) en '{filepath}' para '{city_name_key}'.\")\n",
    "        return keywords\n",
    "    except FileNotFoundError:\n",
    "        logger.error(f\"Archivo de keywords no encontrado para '{city_name_key}' en '{filepath}'.\")\n",
    "        return []\n",
    "    except Exception as e:\n",
    "        logger.error(f\"Error al cargar keywords para '{city_name_key}' desde '{filepath}': {e}\", exc_info=True)\n",
    "        return []\n",
    "\n",
    "# --- Pruebas de la función load_keywords_from_csv (Opcional) ---\n",
    "logger.subsection(\"Probando Carga de Keywords\")\n",
    "\n",
    "# Prueba con una ciudad que debería tener archivo de keywords\n",
    "test_city_existing = 'neuquen' # Asegúrate de tener '0_AGENTE_GOSOM/config/keywords_neuquen.csv'\n",
    "logger.info(f\"Intentando cargar keywords para la ciudad de prueba: '{test_city_existing}'\")\n",
    "keywords_test_existing = load_keywords_from_csv(test_city_existing)\n",
    "\n",
    "if keywords_test_existing:\n",
    "    logger.info(f\"Ejemplo de keywords para {test_city_existing.capitalize()} (primeras 3 si hay): {keywords_test_existing[:3]}\")\n",
    "else:\n",
    "    # El warning o error ya fue logueado por la función load_keywords_from_csv\n",
    "    pass\n",
    "\n",
    "# Prueba con una ciudad que NO debería tener archivo de keywords\n",
    "test_city_non_existing = 'ciudad_totalmente_inventada'\n",
    "logger.info(f\"Intentando cargar keywords para una ciudad de prueba que no existe: '{test_city_non_existing}'\")\n",
    "keywords_test_non_existing = load_keywords_from_csv(test_city_non_existing)\n",
    "# (Se espera un error en el log si el archivo no existe, y la función devuelve [])\n",
    "\n",
    "logger.info(\"Celda 2 completada: Función de carga de keywords definida y probada.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Celda 3 (Completa y Arreglada): Función para Ejecutar el Scraper GOSOM\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-05-30 15:42:55 - INFO - \n",
      "================================================================================\n",
      "DEFINIENDO FUNCIÓN PARA EJECUTAR GOSOM SCRAPER VÍA DOCKER\n",
      "================================================================================\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Prueba de la función run_gmaps_scraper_docker ---\n",
    "# Descomenta CON CUIDADO para probar una ejecución real. Asegúrate de que Docker Desktop esté corriendo.\n",
    "# Y que tengas 'keywords_neuquen.csv' en '0_AGENTE_GOSOM/config/'\n",
    "# Y que 'neuquen' esté definido en GMAPS_COORDINATES en 'parameters_default.json'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-05-30 15:42:55 - INFO - \n",
      "================================================================================\n",
      "PROBANDO EJECUCIÓN DEL SCRAPER GOSOM PARA NEUQUÉN\n",
      "================================================================================\n",
      "2025-05-30 15:42:55 - INFO - [ OK ] Keywords cargadas para 'neuquen' desde 'c:\\BAU\\1 TRABAJO\\REPOSITORIOS\\ETL-GMAPS\\etl-gmaps\\0_AGENTE_GOSOM\\config\\keywords_neuquen.csv': 4 keywords.\n",
      "2025-05-30 15:42:55 - INFO - [INFO] Iniciando prueba de scraping real para: Neuquen con 4 keywords.\n",
      "2025-05-30 15:42:55 - INFO - \n",
      "------------------------------------------------------------\n",
      "Iniciando scraping para ciudad: 'Neuquen'\n",
      "------------------------------------------------------------\n",
      "2025-05-30 15:42:55 - INFO - [INFO] Usando profundidad de búsqueda: 1\n",
      "2025-05-30 15:42:55 - INFO - [INFO] Creando archivo temporal de queries en: c:\\BAU\\1 TRABAJO\\REPOSITORIOS\\ETL-GMAPS\\etl-gmaps\\0_AGENTE_GOSOM\\config\\temp_queries_neuquen_20250530_154255.txt\n",
      "2025-05-30 15:42:55 - INFO - [ OK ] Archivo temporal de queries creado con 4 keywords.\n",
      "2025-05-30 15:42:55 - INFO - [INFO] Creando archivo de salida CSV vacío en: c:\\BAU\\1 TRABAJO\\REPOSITORIOS\\ETL-GMAPS\\etl-gmaps\\0_AGENTE_GOSOM\\data\\raw\\gmaps_data_neuquen_20250530_154255.csv\n",
      "2025-05-30 15:42:55 - INFO - [ OK ] Archivo de salida CSV vacío creado.\n",
      "2025-05-30 15:42:55 - INFO - [INFO] Ejecutando comando Docker: docker run --rm -v c:\\BAU\\1 TRABAJO\\REPOSITORIOS\\ETL-GMAPS\\etl-gmaps\\0_AGENTE_GOSOM\\config:/app/config:ro -v c:\\BAU\\1 TRABAJO\\REPOSITORIOS\\ETL-GMAPS\\etl-gmaps\\0_AGENTE_GOSOM\\data\\raw:/app/data/raw gosom/google-maps-scraper -lang es -depth 1 -input /app/config/temp_queries_neuquen_20250530_154255.txt -results /app/data/raw/gmaps_data_neuquen_20250530_154255.csv -exit-on-inactivity 3m -geo -38.9516,-68.0591\n",
      "2025-05-30 15:42:56 - ERROR - [FAIL] Error durante el scraping para 'neuquen'. Código de retorno: 127\n",
      "2025-05-30 15:42:56 - ERROR - [FAIL] Salida de error estándar del scraper (stderr) en error:\n",
      "docker: error during connect: Head \"http://%2F%2F.%2Fpipe%2FdockerDesktopLinuxEngine/_ping\": open //./pipe/dockerDesktopLinuxEngine: The system cannot find the file specified.\n",
      "\n",
      "Run 'docker run --help' for more information\n",
      "2025-05-30 15:42:56 - INFO - [INFO] Archivo temporal de queries eliminado: c:\\BAU\\1 TRABAJO\\REPOSITORIOS\\ETL-GMAPS\\etl-gmaps\\0_AGENTE_GOSOM\\config\\temp_queries_neuquen_20250530_154255.txt\n",
      "2025-05-30 15:42:56 - ERROR - [FAIL] PRUEBA DE SCRAPING FALLÓ para Neuquen. Revisa los logs.\n"
     ]
    }
   ],
   "source": [
    "# --- Prueba de la función run_gmaps_scraper_docker ---\n",
    "logger.section(\"Probando Ejecución del Scraper GOSOM para Neuquén\")\n",
    "test_city_for_scraping = 'neuquen'\n",
    "keywords_for_scraping_test = load_keywords_from_csv(test_city_for_scraping) # Esto cargará las nuevas keywords que añadiste\n",
    "\n",
    "if keywords_for_scraping_test and GMAPS_COORDINATES.get(test_city_for_scraping.lower()):\n",
    "    logger.info(f\"Iniciando prueba de scraping real para: {test_city_for_scraping.capitalize()} con {len(keywords_for_scraping_test)} keywords.\")\n",
    "    # Usar una profundidad baja para la prueba\n",
    "    results_file = run_gmaps_scraper_docker(keywords_for_scraping_test, test_city_for_scraping, depth_override=1) \n",
    "    if results_file:\n",
    "        logger.success(f\"PRUEBA DE SCRAPING FINALIZADA. Archivo generado: {results_file}\")\n",
    "        try:\n",
    "            if os.path.getsize(results_file) > 0:\n",
    "                logger.info(f\"El archivo de resultados '{results_file}' tiene contenido (tamaño: {os.path.getsize(results_file)} bytes).\")\n",
    "                # Puedes descomentar lo siguiente para ver las primeras filas si tienes gmaps_column_names ya definida\n",
    "                # (pero se define formalmente en Celda 5, así que cuidado con errores de variable no definida aquí)\n",
    "                # df_test_results = pd.read_csv(results_file, header=None, names=gmaps_column_names, nrows=2)\n",
    "                # display(df_test_results)\n",
    "            else:\n",
    "                logger.warning(f\"El archivo de resultados '{results_file}' está vacío.\")\n",
    "        except NameError:\n",
    "             logger.warning(\"Variable 'gmaps_column_names' no definida aún para mostrar preview del CSV en Celda 3.\")\n",
    "        except Exception as e_read:\n",
    "            logger.error(f\"No se pudo leer/verificar el archivo de resultados de prueba: {e_read}\", exc_info=True)\n",
    "    else:\n",
    "        logger.error(f\"PRUEBA DE SCRAPING FALLÓ para {test_city_for_scraping.capitalize()}. Revisa los logs.\")\n",
    "else:\n",
    "    logger.warning(f\"No se ejecutará la prueba de scraping. Faltan keywords o coordenadas para '{test_city_for_scraping}'.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Celda 4: Orquestación del Proceso de Scraping para Ciudades Definidas\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Esta celda utilizará las funciones de las celdas anteriores para iterar sobre una lista de ciudades (o todas las que tengan keywords y coordenadas), ejecutar el scraper para cada una, y recolectar las rutas a los archivos CSV crudos generados."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-05-30 15:42:56 - INFO - \n",
      "================================================================================\n",
      "ORQUESTANDO TAREAS DE SCRAPING\n",
      "================================================================================\n",
      "2025-05-30 15:42:56 - INFO - [INFO] Ciudad 'Neuquen' añadida a la lista de procesamiento (tiene coordenadas y archivo de keywords).\n",
      "2025-05-30 15:42:56 - INFO - [INFO] Ciudad 'General_roca' añadida a la lista de procesamiento (tiene coordenadas y archivo de keywords).\n",
      "2025-05-30 15:42:56 - INFO - [INFO] Ciudad 'Cipolletti' añadida a la lista de procesamiento (tiene coordenadas y archivo de keywords).\n",
      "2025-05-30 15:42:56 - INFO - [INFO] Ciudad 'Allen' añadida a la lista de procesamiento (tiene coordenadas y archivo de keywords).\n",
      "2025-05-30 15:42:56 - INFO - [INFO] Ciudades a procesar en esta ejecución: Neuquen, General_roca, Cipolletti, Allen\n",
      "2025-05-30 15:42:56 - INFO - \n",
      "------------------------------------------------------------\n",
      "Procesando Ciudad: Neuquen\n",
      "------------------------------------------------------------\n",
      "2025-05-30 15:42:56 - INFO - [ OK ] Keywords cargadas para 'neuquen' desde 'c:\\BAU\\1 TRABAJO\\REPOSITORIOS\\ETL-GMAPS\\etl-gmaps\\0_AGENTE_GOSOM\\config\\keywords_neuquen.csv': 4 keywords.\n",
      "2025-05-30 15:42:56 - INFO - [INFO] Intentando scraping para Neuquen con 4 keywords y profundidad 1.\n",
      "2025-05-30 15:42:56 - WARNING - [WARN] MODO SIMULACIÓN: `run_gmaps_scraper_docker` está COMENTADO. Usando archivo dummy si existe.\n",
      "2025-05-30 15:42:56 - WARNING - [WARN] MODO SIMULACIÓN: Archivo dummy NO encontrado en c:\\BAU\\1 TRABAJO\\REPOSITORIOS\\ETL-GMAPS\\etl-gmaps\\0_AGENTE_GOSOM\\data\\raw\\gmaps_data_neuquen_dummy.csv. No habrá datos para esta ciudad en simulación.\n",
      "2025-05-30 15:42:56 - ERROR - [FAIL] Scraping para Neuquen falló o no generó archivo (o archivo dummy no encontrado).\n",
      "2025-05-30 15:42:56 - INFO - \n",
      "------------------------------------------------------------\n",
      "Procesando Ciudad: General_roca\n",
      "------------------------------------------------------------\n",
      "2025-05-30 15:42:56 - INFO - [ OK ] Keywords cargadas para 'general_roca' desde 'c:\\BAU\\1 TRABAJO\\REPOSITORIOS\\ETL-GMAPS\\etl-gmaps\\0_AGENTE_GOSOM\\config\\keywords_general_roca.csv': 2 keywords.\n",
      "2025-05-30 15:42:56 - INFO - [INFO] Intentando scraping para General_roca con 2 keywords y profundidad 1.\n",
      "2025-05-30 15:42:56 - WARNING - [WARN] MODO SIMULACIÓN: `run_gmaps_scraper_docker` está COMENTADO. Usando archivo dummy si existe.\n",
      "2025-05-30 15:42:56 - WARNING - [WARN] MODO SIMULACIÓN: Archivo dummy NO encontrado en c:\\BAU\\1 TRABAJO\\REPOSITORIOS\\ETL-GMAPS\\etl-gmaps\\0_AGENTE_GOSOM\\data\\raw\\gmaps_data_general_roca_dummy.csv. No habrá datos para esta ciudad en simulación.\n",
      "2025-05-30 15:42:56 - ERROR - [FAIL] Scraping para General_roca falló o no generó archivo (o archivo dummy no encontrado).\n",
      "2025-05-30 15:42:56 - INFO - \n",
      "------------------------------------------------------------\n",
      "Procesando Ciudad: Cipolletti\n",
      "------------------------------------------------------------\n",
      "2025-05-30 15:42:56 - WARNING - [WARN] No se encontraron keywords válidas (o el archivo está vacío) en 'c:\\BAU\\1 TRABAJO\\REPOSITORIOS\\ETL-GMAPS\\etl-gmaps\\0_AGENTE_GOSOM\\config\\keywords_cipolletti.csv' para 'cipolletti'.\n",
      "2025-05-30 15:42:56 - WARNING - [WARN] No se cargaron keywords para Cipolletti, se omite el scraping para esta ciudad.\n",
      "2025-05-30 15:42:56 - INFO - \n",
      "------------------------------------------------------------\n",
      "Procesando Ciudad: Allen\n",
      "------------------------------------------------------------\n",
      "2025-05-30 15:42:56 - WARNING - [WARN] No se encontraron keywords válidas (o el archivo está vacío) en 'c:\\BAU\\1 TRABAJO\\REPOSITORIOS\\ETL-GMAPS\\etl-gmaps\\0_AGENTE_GOSOM\\config\\keywords_allen.csv' para 'allen'.\n",
      "2025-05-30 15:42:56 - WARNING - [WARN] No se cargaron keywords para Allen, se omite el scraping para esta ciudad.\n",
      "2025-05-30 15:42:56 - WARNING - [WARN] No se generaron archivos CSV crudos en esta ejecución.\n",
      "2025-05-30 15:42:56 - INFO - [INFO] Celda 4 completada: Orquestación de scraping (o simulación) definida.\n"
     ]
    }
   ],
   "source": [
    "# Celda 4: Orquestación del Proceso de Scraping\n",
    "\n",
    "logger.section(\"Orquestando Tareas de Scraping\")\n",
    "\n",
    "# Lista de ciudades a procesar. Podrías obtenerlas de las claves en GMAPS_COORDINATES\n",
    "# o tener una lista explícita.\n",
    "# Por ahora, procesaremos solo las ciudades para las que tengamos archivos de keywords y coordenadas.\n",
    "\n",
    "cities_to_process = []\n",
    "if GMAPS_COORDINATES and CONFIG_DIR:\n",
    "    for city_key in GMAPS_COORDINATES.keys():\n",
    "        # Verificar si existe un archivo de keywords para esta ciudad\n",
    "        keywords_file_path = os.path.join(CONFIG_DIR, f'keywords_{city_key.lower()}.csv')\n",
    "        if os.path.exists(keywords_file_path):\n",
    "            cities_to_process.append(city_key)\n",
    "            logger.info(f\"Ciudad '{city_key.capitalize()}' añadida a la lista de procesamiento (tiene coordenadas y archivo de keywords).\")\n",
    "        else:\n",
    "            logger.warning(f\"No se encontró archivo de keywords para '{city_key}' en '{keywords_file_path}'. Se omitirá esta ciudad.\")\n",
    "else:\n",
    "    logger.error(\"No hay coordenadas (GMAPS_COORDINATES) o directorio de configuración (CONFIG_DIR) definido. No se pueden determinar ciudades a procesar.\")\n",
    "\n",
    "\n",
    "raw_csv_files_generated = {} # Diccionario para guardar: {'ciudad': 'ruta_al_csv_crudo'}\n",
    "\n",
    "if not cities_to_process:\n",
    "    logger.warning(\"No hay ciudades configuradas para procesar. Revisa GMAPS_COORDINATES y los archivos 'keywords_ciudad.csv'.\")\n",
    "else:\n",
    "    logger.info(f\"Ciudades a procesar en esta ejecución: {', '.join([c.capitalize() for c in cities_to_process])}\")\n",
    "    \n",
    "    for city_key in cities_to_process:\n",
    "        logger.subsection(f\"Procesando Ciudad: {city_key.capitalize()}\")\n",
    "        \n",
    "        keywords = load_keywords_from_csv(city_key)\n",
    "        if not keywords:\n",
    "            logger.warning(f\"No se cargaron keywords para {city_key.capitalize()}, se omite el scraping para esta ciudad.\")\n",
    "            continue\n",
    "\n",
    "        # Aquí puedes decidir la profundidad. Podrías tenerla en GMAPS_COORDINATES por ciudad,\n",
    "        # o usar un valor diferente para pruebas.\n",
    "        # depth_for_city = GMAPS_COORDINATES[city_key].get('depth', DEFAULT_DEPTH) \n",
    "        depth_for_city = 1 # Para el MVP y pruebas rápidas, usar una profundidad baja.\n",
    "        \n",
    "        logger.info(f\"Intentando scraping para {city_key.capitalize()} con {len(keywords)} keywords y profundidad {depth_for_city}.\")\n",
    "        \n",
    "        # --- ESTA LÍNEA EJECUTARÁ DOCKER ---\n",
    "        # (En la prueba real, esto puede tardar varios minutos por ciudad)\n",
    "        # raw_file_path = run_gmaps_scraper_docker(keywords, city_key, depth_override=depth_for_city)\n",
    "        # --- FIN DE LÍNEA QUE EJECUTA DOCKER ---\n",
    "\n",
    "        # --- PARA DESARROLLO SIN EJECUTAR DOCKER CADA VEZ ---\n",
    "        # Simula que el scraper se ejecutó y generó un archivo.\n",
    "        # Asegúrate de tener un archivo de ejemplo en data/raw/ para que esto funcione sin Docker.\n",
    "        # Por ejemplo: data/raw/gmaps_data_neuquen_dummy.csv\n",
    "        logger.warning(\"MODO SIMULACIÓN: `run_gmaps_scraper_docker` está COMENTADO. Usando archivo dummy si existe.\")\n",
    "        dummy_file_name = f\"{RESULTS_FILENAME_PREFIX}{city_key.lower()}_dummy.csv\"\n",
    "        dummy_file_path = os.path.join(RAW_CSV_FOLDER, dummy_file_name)\n",
    "        if os.path.exists(dummy_file_path):\n",
    "            raw_file_path = dummy_file_path\n",
    "            logger.info(f\"MODO SIMULACIÓN: Usando archivo dummy existente: {raw_file_path}\")\n",
    "        else:\n",
    "            raw_file_path = None\n",
    "            logger.warning(f\"MODO SIMULACIÓN: Archivo dummy NO encontrado en {dummy_file_path}. No habrá datos para esta ciudad en simulación.\")\n",
    "        # --- FIN DE SECCIÓN DE SIMULACIÓN ---\n",
    "\n",
    "        if raw_file_path and os.path.exists(raw_file_path):\n",
    "            raw_csv_files_generated[city_key] = raw_file_path\n",
    "            logger.success(f\"Scraping para {city_key.capitalize()} simulado/completado. Archivo: {raw_file_path}\")\n",
    "        else:\n",
    "            logger.error(f\"Scraping para {city_key.capitalize()} falló o no generó archivo (o archivo dummy no encontrado).\")\n",
    "\n",
    "if raw_csv_files_generated:\n",
    "    logger.success(f\"Proceso de scraping (o simulación) finalizado. Archivos crudos generados:\")\n",
    "    for city, path in raw_csv_files_generated.items():\n",
    "        logger.info(f\"  - {city.capitalize()}: {path}\")\n",
    "else:\n",
    "    logger.warning(\"No se generaron archivos CSV crudos en esta ejecución.\")\n",
    "\n",
    "logger.info(\"Celda 4 completada: Orquestación de scraping (o simulación) definida.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Celda 5: Carga y Transformación de Datos\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-05-30 15:42:56 - INFO - \n",
      "================================================================================\n",
      "CARGANDO Y TRANSFORMANDO DATOS EXTRAÍDOS\n",
      "================================================================================\n",
      "2025-05-30 15:42:56 - WARNING - [WARN] No hay archivos CSV crudos para procesar (variable 'raw_csv_files_generated' está vacía).\n",
      "2025-05-30 15:42:56 - WARNING - [WARN] No se procesaron datos de ninguna ciudad. El DataFrame final está vacío.\n",
      "2025-05-30 15:42:56 - INFO - [INFO] Celda 5 completada: Carga y transformación de datos definida.\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ejemplo de deduplicación (añadir después de concatenar en Celda 5)\n",
    "if not final_df_all_cities.empty:\n",
    "    logger.subsection(\"Aplicando Deduplicación de Prospectos\")\n",
    "    # Deduplicar basado en el link de Google Maps, manteniendo la primera aparición\n",
    "    # Podrías necesitar una lógica más sofisticada si los links no son siempre perfectos o si quieres fusionar info\n",
    "    initial_count = len(final_df_all_cities)\n",
    "    final_df_all_cities.drop_duplicates(subset=['link'], keep='first', inplace=True)\n",
    "    deduplicated_count = initial_count - len(final_df_all_cities)\n",
    "    if deduplicated_count > 0:\n",
    "        logger.success(f\"Se eliminaron {deduplicated_count} prospectos duplicados basados en la columna 'link'.\")\n",
    "    else:\n",
    "        logger.info(\"No se encontraron duplicados basados en la columna 'link' o ya estaban limpios.\")\n",
    "    logger.info(f\"Total de prospectos únicos después de deduplicación: {len(final_df_all_cities)}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Celda 6: Guardado de Datos Procesados (a un único CSV por ahora)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-05-30 15:42:56 - INFO - \n",
      "================================================================================\n",
      "GUARDANDO DATOS PROCESADOS Y LIMPIOS\n",
      "================================================================================\n",
      "2025-05-30 15:42:56 - WARNING - [WARN] No hay datos procesados para guardar (DataFrame final está vacío).\n",
      "2025-05-30 15:42:56 - INFO - [INFO] Celda 6 completada: Proceso de guardado de datos procesados definido.\n"
     ]
    }
   ],
   "source": [
    "# Celda 6: Guardado de Datos Procesados\n",
    "\n",
    "logger.section(\"Guardando Datos Procesados y Limpios\")\n",
    "\n",
    "if not final_df_all_cities.empty:\n",
    "    timestamp_save = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "    processed_filename = f\"gmaps_prospectos_consolidados_{timestamp_save}.csv\"\n",
    "    \n",
    "    if PROCESSED_CSV_FOLDER: # Verificar que la carpeta de destino esté definida\n",
    "        processed_filepath = os.path.join(PROCESSED_CSV_FOLDER, processed_filename)\n",
    "        try:\n",
    "            final_df_all_cities.to_csv(processed_filepath, index=False, encoding='utf-8-sig') # utf-8-sig para mejor compatibilidad con Excel\n",
    "            logger.success(f\"Datos procesados consolidados guardados en: {processed_filepath}\")\n",
    "            logger.info(f\"Total de {len(final_df_all_cities)} prospectos guardados.\")\n",
    "        except Exception as e:\n",
    "            logger.error(f\"Error al guardar el archivo CSV procesado en '{processed_filepath}': {e}\", exc_info=True)\n",
    "    else:\n",
    "        logger.error(\"PROCESSED_CSV_FOLDER no está definido. No se puede guardar el archivo procesado.\")\n",
    "elif raw_csv_files_generated and not all_processed_data : # Hubo archivos crudos pero no se procesó nada\n",
    "    logger.warning(\"Se generaron archivos crudos pero no se pudieron procesar o resultaron vacíos. No se guardará archivo consolidado.\")\n",
    "else: # No hubo archivos crudos para empezar\n",
    "    logger.warning(\"No hay datos procesados para guardar (DataFrame final está vacío).\")\n",
    "\n",
    "logger.info(\"Celda 6 completada: Proceso de guardado de datos procesados definido.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
