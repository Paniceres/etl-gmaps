# ğŸ‰ Agente GOSOM ETL - EspecificaciÃ³n de la Interfaz Streamlit ğŸš€

## ğŸ¯ Objetivo General de la UI

Proporcionar una interfaz web âœ¨ simple y amigable âœ¨ para configurar y ejecutar tareas de scraping de Google Maps con el Agente GOSOM, monitorear su progreso y visualizar/descargar los resultados procesados.

## ğŸ“ Layout General

-   ğŸ–¥ï¸ **Barra Lateral (Sidebar):** Para configuraciones principales y acciones importantes.
-   ğŸ“Š **Ãrea Principal (Main Area):** Para mostrar logs, resultados detallados, tablas de datos y grÃ¡ficos estadÃ­sticos.

## ğŸ› ï¸ Componentes y Funcionalidades Detalladas

### 1. âš™ï¸ ConfiguraciÃ³n de la Tarea de Scraping (Sidebar)

Esta secciÃ³n permite al usuario definir los parÃ¡metros para la ejecuciÃ³n del scraping.

-   âœ¨ **TÃ­tulo:** "Configurar Nueva Tarea de Scraping"
-   ğŸŒ **Widget 1: SelecciÃ³n de Ciudad(es)**
    -   **Tipo:** `st.multiselect` (para seleccionar una o varias ciudades).
    -   **Opciones:** Cargadas dinÃ¡micamente desde las **claves** del diccionario `GMAPS_COORDINATES` (ej. "NeuquÃ©n", "General Roca", etc.) que se encuentran en `parameters_default.json`.
    -   **Label:** **"Seleccionar Ciudad(es) a Procesar"**
-   ğŸ“ **Widget 2: GestiÃ³n de Keywords (DinÃ¡mico segÃºn ciudad seleccionada)**
    -   Una vez que se selecciona una o mÃ¡s ciudades, se mostrarÃ¡ un Ã¡rea de texto para cada una.
    -   El contenido inicial del `st.text_area` se **pre-poblarÃ¡** con las keywords cargadas desde el archivo `keywords_<ciudad>.csv` correspondiente utilizando la funciÃ³n `load_keywords_from_csv()`.
    -   Se permitirÃ¡ al usuario **editar**, **aÃ±adir** o **eliminar** keywords directamente en esta Ã¡rea de texto.
    -   **Label:** **"Keywords para [Nombre de la Ciudad Seleccionada]"**
    -   â¡ï¸ **BotÃ³n (Opcional para el futuro):** **"Guardar Keywords para [Ciudad]"** (ImplementaciÃ³n para actualizar el archivo CSV en disco).
-   ğŸ” **Widget 3: Profundidad de BÃºsqueda (`depth`)**
    -   **Tipo:** `st.number_input` (mÃ¡s preciso) o `st.slider` (mÃ¡s visual).
    -   **Label:** **"Profundidad de BÃºsqueda"**
    -   **Valor por defecto:** Se leerÃ¡ del parÃ¡metro `DEFAULT_DEPTH` definido en `parameters_default.json`.
    -   **Rango Min/Max:** Por ejemplo, de **1** a **20**.
-   ğŸ“§ **Widget 4: Activar ExtracciÃ³n de Emails**
    -   **Tipo:** `st.checkbox`.
    -   **Label:** **"Â¿Extraer Emails? (Puede tardar mÃ¡s)"**
    -   **Valor por defecto:** **`True`** (segÃºn el requisito actualizado).
-   â–¶ï¸ **Widget 5: BotÃ³n de Inicio**
    -   **Tipo:** `st.button`.
    -   **Label:** **"ğŸš€ Iniciar Scraping"**

### 2. ğŸ“ˆ Monitoreo de Progreso (Main Area)

Esta secciÃ³n mantendrÃ¡ informado al usuario sobre el estado de la ejecuciÃ³n.

-   âœ¨ **TÃ­tulo:** "Progreso de la Tarea"
-   â³ **Indicador de Actividad:** Se mostrarÃ¡ un `st.spinner("Scraping en progreso...")` mientras la tarea estÃ© activa.
-   ğŸ“œ **Log del Proceso:**
    -   **ImplementaciÃ³n MVP (Actual):** Mostrar el contenido completo del archivo de log (`agent_gmaps_mvp.log`) una vez que la tarea haya **finalizado**.
    -   **Mejora (Ideal):** Mostrar las **Ãºltimas N lÃ­neas** del log en **tiempo real** (requiere manejo de estado avanzado o ejecuciÃ³n no bloqueante del proceso de scraping).
    -   **VisualizaciÃ³n:** Utilizar `st.text_area` o `st.code` para presentar los logs de forma legible.
-   ğŸš§ **Barra de Progreso (Opcional Avanzado):** Si es posible estimar el nÃºmero total de operaciones, se podrÃ­a aÃ±adir un `st.progress`.

### 3. ğŸ“Š VisualizaciÃ³n de Resultados (Main Area - PestaÃ±as o Secciones)

Una vez completado el scraping y el procesamiento, se mostrarÃ¡n los resultados. Esta secciÃ³n podrÃ­a organizarse en pestaÃ±as o sub-secciones claras.

-   ğŸ“ **PestaÃ±a/SecciÃ³n 1: Datos Crudos (por ciudad)**
    -   Se permitirÃ¡ seleccionar una ciudad de las que fueron procesadas en la ejecuciÃ³n actual.
    -   Mostrar una **vista previa** (`st.dataframe`) del DataFrame cargado directamente del CSV crudo (la salida original de GOSOM).
    -   Incluir una **opciÃ³n de descarga** (`st.download_button`) para obtener el CSV crudo especÃ­fico de la ciudad seleccionada.
-   âœ… **PestaÃ±a/SecciÃ³n 2: Datos Procesados y Consolidados**
    -   Mostrar el **DataFrame final consolidado** (`final_df_all_cities`) que combina los datos procesados de todas las ciudades utilizando `st.dataframe`.
    -   AÃ±adir un **botÃ³n de descarga** (`st.download_button`) con el label **"Descargar CSV Procesado Consolidado"**.
-   ğŸ“ˆ **PestaÃ±a/SecciÃ³n 3: Resumen y EstadÃ­sticas (Mini-EDA)**
    -   Proporcionar un anÃ¡lisis rÃ¡pido y visual de los resultados.
    -   **Contadores (`st.metric`):**
        -   ğŸ”¢ **Total de prospectos extraÃ­dos.**
        -   ğŸ“§ **Total de prospectos con email.**
        -   ğŸŒ **Total de prospectos con sitio web.**
        -   ğŸ™ï¸ **NÃºmero de prospectos por ciudad de origen.**
    -   **GrÃ¡ficos:**
        -   ğŸ“Š **GrÃ¡fico de barras (`st.bar_chart`)** mostrando las **top N categorÃ­as** de negocios encontradas.
        -   ğŸ—ºï¸ **Mapa de dispersiÃ³n simple (`st.map`)** de los prospectos si se han extraÃ­do las coordenadas geogrÃ¡ficas.

### 4. ğŸ“‚ GestiÃ³n de Archivos de ConfiguraciÃ³n (Opcional Avanzado - Sidebar)

Funcionalidad para gestionar los archivos que controlan la configuraciÃ³n.

-   ğŸ‘€ **Visualizar/Editar:** Posibilidad de ver y, con precauciÃ³n, editar el contenido del archivo `parameters_default.json`.
-   â¬†ï¸ **Subir Archivos:** OpciÃ³n para subir nuevos archivos de keywords en formato CSV.

## ğŸ§© LÃ³gica de Backend (Funciones a Reutilizar/Adaptar)

Se integrarÃ¡n y adaptarÃ¡n funciones existentes, principalmente del notebook MVP.

-   `load_keywords_from_csv(city_name_key)`: Para cargar las palabras clave.
-   `run_gmaps_scraper_docker(keywords_list, city_name_key, depth_override, extract_emails_flag)`: Adaptar para aceptar el flag de extracciÃ³n de emails.
-   `transform_gmaps_data(df_raw, city_key_origin)`: Para procesar los DataFrames crudos.
-   La lÃ³gica de **orquestaciÃ³n** de la Celda 4 (en el notebook): Adaptarla para que se ejecute de forma secuencial o paralela al presionar el botÃ³n "Iniciar Scraping".
-   La lÃ³gica de **carga y combinaciÃ³n** de la Celda 5 (en el notebook): Para consolidar los resultados.

## ğŸš¶â€â™‚ï¸ Flujo de Usuario

1.  Usuario abre la aplicaciÃ³n Streamlit en su navegador.
2.  En la barra lateral, **selecciona** la(s) ciudad(es), **revisa/edita** las palabras clave asociadas, **ajusta** la profundidad de bÃºsqueda y **marca** la opciÃ³n de extracciÃ³n de emails si la necesita.
3.  Presiona el botÃ³n **"ğŸš€ Iniciar Scraping"**.
4.  En el Ã¡rea principal, la UI muestra un **indicador de progreso** y el **registro (log)** de la ejecuciÃ³n.
5.  Al finalizar la tarea, se muestran los **resultados procesados** en tablas y los **grÃ¡ficos de estadÃ­sticas**.
6.  El usuario puede **descargar** los archivos CSV consolidados o individuales.

## ğŸ§  Consideraciones TÃ©cnicas

-   Keeping ğŸ§  **Manejo de estado de Streamlit:** Es crucial para mantener la informaciÃ³n persistente entre las re-ejecuciones de la aplicaciÃ³n, especialmente para procesos largos o cuando se necesita recordar selecciones del usuario.
-   Running ğŸƒâ€â™‚ï¸ **EjecuciÃ³n de `subprocess` (para Docker):** Considerar si se ejecutarÃ¡ de forma bloqueante (mÃ¡s simple) o no bloqueante (permite log en tiempo real, pero es mÃ¡s compleja).
-   File ğŸ“‚ **Rutas de archivos:** Asegurarse de que todas las rutas a archivos de log, configuraciÃ³n y datos crudos sean correctas y relativas al script de Streamlit.
